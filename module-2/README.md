# Module 2 - Generative AI Basics

This **Generative AI learning path** is designed to help you build your knowledge and skills in Generative AI, but instead of connecting to a cloud-based model, we will be using a **Local Large Language Model (Local LLM)** for our learning journey. This has a few advantages, such as privacy, cost, and the ability to use a wide variety of local LLMs. In other words, running your local LLM enables the **democratisation of AI**, allowing you to experiment and use different models without the worry of incurring high costs.

**Privacy**: You can use your own data and models without sharing them with a cloud provider.

**Cost**: You can run your models on your own hardware, which can be more cost-effective than cloud-based solutions, so you can experiment with different models without the worry of incurring high costs.

**Variety of LLMs**: There are many LLMs available that can be run locally, and you can choose the one that best fits your needs. You can also customise and fine-tune these models to suit your specific requirements.

## Introduction to Generative AI

Generative AI refers to a type of artificial intelligence that can create new data, such as images, videos, music, or text, rather than simply processing and analysing existing data. This is achieved through various algorithms and techniques, including machine learning, deep learning, and neural networks.

Generative AI burst into the mainstream towards the end of 2022, with the release of OpenAI's GPT-3, which is one of the most advanced generative models available. Since then, there have been many other models released, each with its own unique capabilities and use cases.

### Open AI Chat Completions API

OpenAI built the [chat completions API](https://platform.openai.com/docs/guides/text-generation/chat-completions-api) shortly after the release of GPT-3, which allows developers to build chatbots and other conversational AI applications using the GPT-3 model. This API has been used to build a wide range of applications, from customer service chatbots to creative writing tools.

Many other LLM models have been released since then, each with its own unique capabilities and use cases. However, these models have their own APIs, which can be challenging to use and integrate into your applications.

### New Generation AI Developer Tools

This is where this new generation developer tools come in. Applications like [LM Studio](https://lmstudio.ai/) and [Ollama](https://ollama.com/) enable developers to run these models locally, making it easier to experiment with different models and integrate them into your applications. In addition to that, they have Open AI compatibility, so that irregardless of the model you are using, you can still use the Open AI API.

This is a game changer, because, it will **allow one to experiment with different models without the need to change the code**. 

For this learning path, we will be using **[LM Studio](https://lmstudio.ai/)** to build our Generative AI applications.

## Access to LLM using Python

## Online vs Local LLM

## Setting up your local LLM

## Generative AI Libraries